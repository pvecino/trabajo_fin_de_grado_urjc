{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical computation\n",
    "import numpy as np\n",
    "import itertools\n",
    "from random import randint\n",
    "\n",
    "\n",
    "# import sklearn\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def opened (path=''):\n",
    "    \n",
    "    X_training=[]\n",
    "    X_testing=[]\n",
    "    y_training=[]\n",
    "    y_testing=[]\n",
    "           \n",
    "    for j in range(0, 50):\n",
    "        X_training.append(pd.read_csv('test_train_dataset{}{}_X_train.csv'.format(path,j)))\n",
    "        X_testing.append(pd.read_csv('test_train_dataset{}{}_X_test.csv'.format(path, j)))\n",
    "        y_training.append(pd.read_csv('test_train_dataset{}{}_y_train.csv'.format(path, j)))\n",
    "        y_testing.append(pd.read_csv('test_train_dataset{}{}_y_test.csv'.format(path, j)))\n",
    "        \n",
    "    return X_training, X_testing, y_training, y_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency (valor):\n",
    "    max = 0\n",
    "    res = list(valor)[0] \n",
    "    for i in list(valor): \n",
    "        freq = list(valor).count(i) \n",
    "        if freq > max: \n",
    "            max = freq \n",
    "            res = i \n",
    "    valor = res\n",
    "    return valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximun (df, name):\n",
    "    maximun = df.sort_values(by='accuracy_validation',ascending=False).head(n=1)\n",
    "    best = list(maximun[name])[0]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters(i):\n",
    "    max_layers = 60#204\n",
    "    min_layers = 10#5\n",
    "    switcher={\n",
    "            'activation':[ 'tanh', 'relu'],\n",
    "            'solver': ['sgd'], #['sgd', 'adam'],\n",
    "            'hidden_layer_sizes':[(i,) for i in range(min_layers,max_layers, 2)]\n",
    "         }\n",
    "    return switcher.get(i,\"Invalid parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Layersint(Layers):\n",
    "    Layers = tuple(Layers)\n",
    "    maxi=len(Layers)\n",
    "    cal=0\n",
    "    res=[]\n",
    "    for i in range(0, maxi):\n",
    "        if Layers[i]==\"(\" or Layers[i]==\",\" or Layers[i]==\")\":\n",
    "            res += str(Layers[i])\n",
    "        else:\n",
    "            if maxi==6:\n",
    "                if i==1:\n",
    "                    cal = int(Layers[i])*100\n",
    "                elif i==2:\n",
    "                    cal += int(Layers[i])*10\n",
    "                else:\n",
    "                    cal +=int(Layers[i])\n",
    "            elif maxi==5:\n",
    "                if i==1:\n",
    "                    cal = int(Layers[i])*10\n",
    "                else:\n",
    "                    cal += int(Layers[i])\n",
    "            else:\n",
    "                cal = int(Layers[i])\n",
    "\n",
    "    return cal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aplicación del algoritmo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_MLP(path, features, name, param, multiclass=False):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = opened(path=path)\n",
    "    print('Terminada la apertura de BBDD')\n",
    "    \n",
    "    param_grid = [\n",
    "        {\n",
    "            param: parameters(param)\n",
    "        }\n",
    "       ]\n",
    "    MLP_evaluate=[]\n",
    "    MLP_acc_model=[]\n",
    "    MLP_std=[]\n",
    "\n",
    "    best_param=[]\n",
    "    \n",
    "    if param == 'hidden_layer_sizes':\n",
    "        rest = ['activation', 'solver']\n",
    "        resto=[]\n",
    "        for r in rest:\n",
    "            resto.append(pd.read_csv('results/MLP/MLP_hyper_{}_{}.csv'.format(r, name)))\n",
    "\n",
    "        Activation = (maximun(resto[0], rest[0]))\n",
    "        print(Activation)\n",
    "        Solver = (maximun(resto[1], rest[1]))\n",
    "        print(Solver)\n",
    "        \n",
    "        model = MLPClassifier(max_iter=400, learning_rate_init=0.2, \n",
    "                              learning_rate='invscaling', alpha = 1.0, \n",
    "                              solver=Solver, activation=Activation) \n",
    "    else:\n",
    "        model = MLPClassifier(max_iter=400, learning_rate_init=0.2,\n",
    "                              learning_rate='invscaling', alpha = 1.0)\n",
    "        \n",
    "    for j in range(0, 50):\n",
    "        \n",
    "        droping=pd.concat([x_train[j][features], y_train[j]], axis=1,sort=False)\n",
    "        droping=droping.drop_duplicates(subset=features, keep=False)\n",
    "        xtrain= droping[features]\n",
    "        if multiclass==True:\n",
    "            ytrain=droping['CRG']\n",
    "        else:\n",
    "            ytrain=droping[['HP', 'Diabetes', 'Otros']]\n",
    "                \n",
    "        print('Particion: ', j)\n",
    "    #Normalizamos los datos de test y de train\n",
    "        ss=StandardScaler()\n",
    "        ss.fit(xtrain)\n",
    "        ss_train=ss.transform(xtrain)\n",
    "        #Buscamos los mejores parametros para esa división normalizada    \n",
    "        clf = GridSearchCV(model, param_grid,\n",
    "                           cv=KFold(n_splits=5), scoring='accuracy', n_jobs=-1)\n",
    "        if multiclass==True:\n",
    "            y_training = ytrain.values.ravel()\n",
    "        else:\n",
    "            y_training = ytrain\n",
    "\n",
    "        clf.fit(ss_train,y_training)\n",
    "\n",
    "        best_index_Acc = np.nonzero(clf.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "        best_param.append(clf.best_params_[param])\n",
    "        MLP_acc_model.append(clf.cv_results_['mean_test_score'][best_index_Acc])\n",
    "        MLP_std.append(clf.cv_results_['std_test_score'][best_index_Acc])\n",
    "\n",
    "        MLP_evaluate.append([best_param[j],  round(MLP_acc_model[j],3),round(MLP_std[j],3)])\n",
    "\n",
    "    labels_comp = [param , 'accuracy_validation', 'std']\n",
    "\n",
    "    comparacion=pd.DataFrame(data=MLP_evaluate, columns = labels_comp)\n",
    "    comparacion.to_csv('results/MLP/MLP_hyper_{}_{}.csv'.format(param, name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_MLP(path, features, name, multiclass=False):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = opened(path=path)\n",
    "    print('Terminada la apertura de BBDD')\n",
    "    \n",
    "    param= ['activation', 'solver', 'hidden_layer_sizes']\n",
    "    comparacion=[]\n",
    "    for p in param:\n",
    "        comparacion.append(pd.read_csv('results/MLP/MLP_hyper_{}_{}.csv'.format(p, name)))\n",
    "    \n",
    "    Activation = (maximun(comparacion[0], param[0]))\n",
    "    print(Activation)\n",
    "    Solver = (maximun(comparacion[1], param[1]))\n",
    "    print(Solver)\n",
    "    Layer = Layersint(maximun(comparacion[2], param[2]))\n",
    "    print(Layer)\n",
    "    print('Con los parámetros óptimos procedemos a clasificar.')\n",
    "    \n",
    "    accuracy=[]\n",
    "    hamming_losse=[]\n",
    "    precision_macro=[]\n",
    "    precision_micro=[]\n",
    "    recall_macro=[]\n",
    "    recall_micro=[]\n",
    "    f1_scores_macro=[]\n",
    "    f1_scores_micro=[]\n",
    "    \n",
    "    average_accuracy=[]\n",
    "    average_precision=[]\n",
    "    average_recall=[]\n",
    "    f1_scores=[]\n",
    "    \n",
    "    for i in range(0,50):\n",
    "        droping_train=pd.concat([x_train[i][features], y_train[i]], axis=1,sort=False)\n",
    "        droping_train=droping_train.drop_duplicates(subset=features, keep=False)\n",
    "        xtrain= droping_train[features]\n",
    "        if multiclass==True:\n",
    "            ytrain=droping_train['CRG']\n",
    "        else:\n",
    "            ytrain=droping_train[['HP', 'Diabetes', 'Otros']]\n",
    "\n",
    "        droping_test=pd.concat([x_test[i][features], y_test[i]], axis=1,sort=False)\n",
    "        droping=droping_test.drop_duplicates(subset=features, keep=False)\n",
    "        xtest= droping_test[features]\n",
    "        if multiclass==True:\n",
    "            ytest=droping_test['CRG']\n",
    "        else:\n",
    "            ytest=droping_test[['HP', 'Diabetes', 'Otros']]\n",
    "                \n",
    "        ss=StandardScaler()\n",
    "        ss.fit(xtrain)\n",
    "        ss_train=ss.transform(xtrain)\n",
    "        ss_test=ss.transform(xtest)\n",
    "\n",
    "        clf= MLPClassifier(max_iter=400, learning_rate_init=0.2, activation=Activation, \n",
    "                           solver=Solver, hidden_layer_sizes= (Layer,), alpha = 1.0, \n",
    "                           learning_rate='invscaling')\n",
    "        \n",
    "        if multiclass==True:\n",
    "            y_training = ytrain.values.ravel()\n",
    "        else:\n",
    "            y_training = ytrain\n",
    "               \n",
    "        clf.fit(ss_train,y_training)\n",
    "\n",
    "    #Predecimos el algoritmo con el mejor K\n",
    "        y_true, y_pred = ytest, clf.predict(ss_test)\n",
    "        \n",
    "        if multiclass==False:\n",
    "            accuracy.append(accuracy_score(y_true, y_pred))\n",
    "            hamming_losse.append(hamming_loss(y_true, y_pred))\n",
    "            precision_macro.append(precision_score(y_true,y_pred, average='macro'))\n",
    "            precision_micro.append(precision_score(y_true,y_pred, average='micro'))\n",
    "            recall_macro.append(recall_score(y_true, y_pred, average='macro'))\n",
    "            recall_micro.append(recall_score(y_true, y_pred, average='micro'))\n",
    "            f1_scores_macro.append(f1_score(y_true, y_pred, average='macro'))\n",
    "            f1_scores_micro.append(f1_score(y_true, y_pred, average='micro'))\n",
    "        else:\n",
    "            cm = confusion_matrix(y_true,y_pred)\n",
    "            TP = np.diag(cm)\n",
    "            FP = np.sum(cm, axis=0) - TP\n",
    "            FN = np.sum(cm, axis=1) - TP\n",
    "            #num_classes = len(TP)\n",
    "            #TN = []\n",
    "            #for i in range(num_classes):\n",
    "            #    temp = np.delete(cm, i, 0)    # delete ith row\n",
    "            #    temp = np.delete(temp, i, 1)  # delete ith column\n",
    "            #    TN.append(sum(sum(temp)))\n",
    "\n",
    "            precision=TP / (TP + FP)\n",
    "            recall=TP / (TP + FN)\n",
    "\n",
    "            average_precision.append(np.mean(TP / (TP + FP)))\n",
    "            average_recall.append(np.mean(TP / (TP + FN)))\n",
    "            f1_scores.append(np.mean(2*(precision*recall)/(precision+recall)))\n",
    "            average_accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    predict=pd.DataFrame()\n",
    "    if multiclass==False:\n",
    "        predict['accuracy']=accuracy\n",
    "        predict['hamming_loss'] = hamming_losse\n",
    "        predict['precision_macro']=precision_macro\n",
    "        predict['precision_micro']=precision_micro\n",
    "        predict['recall_macro']=recall_macro\n",
    "        predict['recall_micro']=recall_micro\n",
    "        predict['f1_macro']=f1_scores_macro\n",
    "        predict['f1_micro']=f1_scores_micro\n",
    "    else:\n",
    "        predict['accuracy']=average_accuracy\n",
    "        predict['precision']=average_precision\n",
    "        predict['recall']=average_recall\n",
    "        predict['f1']=f1_scores\n",
    "    predict.to_csv('results/MLP/MLP_predict_{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Caracteriticas: Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "param= ['activation', 'solver', 'hidden_layer_sizes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ocurrencia_all', 'ocurrencia_ill', 'presencia_all', 'presencia_ill'] \n",
    "features_freq = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/freq_{}.txt\".format(n), \"r\") as file:\n",
    "        features_freq.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_CLASS = ['/class/O_WC_A_','/class/O_WC_WO_' , '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "names_CLASS_fr=['freq_all_class_O', 'freq_ill_class_O', 'freq_all_class_P', 'freq_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: freq_all_class_O activation\n",
      "Ya existe el hyperparametro: freq_all_class_O solver\n",
      "Ya existe el hyperparametro: freq_all_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: freq_all_class_O\n",
      "Ya existe el hyperparametro: freq_ill_class_O activation\n",
      "Ya existe el hyperparametro: freq_ill_class_O solver\n",
      "Ya existe el hyperparametro: freq_ill_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: freq_ill_class_O\n",
      "Ya existe el hyperparametro: freq_all_class_P activation\n",
      "Ya existe el hyperparametro: freq_all_class_P solver\n",
      "Ya existe el hyperparametro: freq_all_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: freq_all_class_P\n",
      "Ya existe el hyperparametro: freq_ill_class_P activation\n",
      "Ya existe el hyperparametro: freq_ill_class_P solver\n",
      "Ya existe el hyperparametro: freq_ill_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: freq_ill_class_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(paths_CLASS, names_CLASS_fr, features_freq):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m, True)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "\n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n, True)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_LABEL = ['/label/O_WL_A_','/label/O_WL_WO_' , '/label/P_WL_A_', '/label/P_WL_WO_']\n",
    "names_LABEL_fr=['freq_all_label_O', 'freq_ill_label_O', 'freq_all_label_P', 'freq_ill_label_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: freq_all_label_O activation\n",
      "Ya existe el hyperparametro: freq_all_label_O solver\n",
      "Ya existe el hyperparametro: freq_all_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: freq_all_label_O\n",
      "Ya existe el hyperparametro: freq_ill_label_O activation\n",
      "Ya existe el hyperparametro: freq_ill_label_O solver\n",
      "Ya existe el hyperparametro: freq_ill_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: freq_ill_label_O\n",
      "Ya existe el hyperparametro: freq_all_label_P activation\n",
      "Ya existe el hyperparametro: freq_all_label_P solver\n",
      "Ya existe el hyperparametro: freq_all_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: freq_all_label_P\n",
      "Ya existe el hyperparametro: freq_ill_label_P activation\n",
      "Ya existe el hyperparametro: freq_ill_label_P solver\n",
      "Ya existe el hyperparametro: freq_ill_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: freq_ill_label_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(paths_LABEL, names_LABEL_fr, features_freq):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "    \n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Caracteriticas: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['label_o_all','label_o_ill', 'label_p_all', 'label_p_ill']\n",
    "features_rf_label = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/rf_{}.txt\".format(n), \"r\") as file:\n",
    "        features_rf_label.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label= ['/label/O_WL_A_', '/label/O_WL_WO_', '/label/P_WL_A_', '/label/P_WL_WO_']\n",
    "names_label_rf=['rf_all_label_O','rf_ill_label_O', 'rf_all_label_P', 'rf_ill_label_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: rf_all_label_O activation\n",
      "Ya existe el hyperparametro: rf_all_label_O solver\n",
      "Ya existe el hyperparametro: rf_all_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: rf_all_label_O\n",
      "Ya existe el hyperparametro: rf_ill_label_O activation\n",
      "Ya existe el hyperparametro: rf_ill_label_O solver\n",
      "Ya existe el hyperparametro: rf_ill_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: rf_ill_label_O\n",
      "Ya existe el hyperparametro: rf_all_label_P activation\n",
      "Ya existe el hyperparametro: rf_all_label_P solver\n",
      "Ya existe el hyperparametro: rf_all_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: rf_all_label_P\n",
      "Ya existe el hyperparametro: rf_ill_label_P activation\n",
      "Ya existe el hyperparametro: rf_ill_label_P solver\n",
      "Ya existe el hyperparametro: rf_ill_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: rf_ill_label_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(path_label, names_label_rf, features_rf_label):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "    \n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['class_o_all','class_o_ill', 'class_p_all', 'class_p_ill']\n",
    "features_rf_class = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/rf_{}.txt\".format(n), \"r\") as file:\n",
    "        features_rf_class.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class= ['/class/O_WC_A_', '/class/O_WC_WO_', '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "name_class_rf=['rf_all_class_O','rf_ill_class_O', 'rf_all_class_P', 'rf_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: rf_all_class_O activation\n",
      "Ya existe el hyperparametro: rf_all_class_O solver\n",
      "Ya existe el hyperparametro: rf_all_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: rf_all_class_O\n",
      "Ya existe el hyperparametro: rf_ill_class_O activation\n",
      "Ya existe el hyperparametro: rf_ill_class_O solver\n",
      "Ya existe el hyperparametro: rf_ill_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: rf_ill_class_O\n",
      "Ya existe el hyperparametro: rf_all_class_P activation\n",
      "Ya existe el hyperparametro: rf_all_class_P solver\n",
      "Ya existe el hyperparametro: rf_all_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: rf_all_class_P\n",
      "Ya existe el hyperparametro: rf_ill_class_P activation\n",
      "Ya existe el hyperparametro: rf_ill_class_P solver\n",
      "Ya existe el hyperparametro: rf_ill_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: rf_ill_class_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(path_class, name_class_rf, features_rf_class):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m,True)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "    \n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n, True)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de caracteristicas: F Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['label_o_all','label_o_ill', 'label_p_all', 'label_p_ill']\n",
    "features_fc_label = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/fc_{}.txt\".format(n), \"r\") as file:\n",
    "        features_fc_label.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label= ['/label/O_WL_A_', '/label/O_WL_WO_', '/label/P_WL_A_', '/label/P_WL_WO_']\n",
    "names_label_fc=['fc_all_label_O','fc_ill_label_O', 'fc_all_label_P', 'fc_ill_label_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: fc_all_label_O activation\n",
      "Ya existe el hyperparametro: fc_all_label_O solver\n",
      "Ya existe el hyperparametro: fc_all_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_O\n",
      "Ya existe el hyperparametro: fc_ill_label_O activation\n",
      "Ya existe el hyperparametro: fc_ill_label_O solver\n",
      "Ya existe el hyperparametro: fc_ill_label_O hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_O\n",
      "Ya existe el hyperparametro: fc_all_label_P activation\n",
      "Ya existe el hyperparametro: fc_all_label_P solver\n",
      "Ya existe el hyperparametro: fc_all_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_P\n",
      "Ya existe el hyperparametro: fc_ill_label_P activation\n",
      "Ya existe el hyperparametro: fc_ill_label_P solver\n",
      "Ya existe el hyperparametro: fc_ill_label_P hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(path_label, names_label_fc, features_fc_label):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "    \n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['class_o_all','class_o_ill', 'class_p_all', 'class_p_ill']\n",
    "features_fc_class = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/rf_{}.txt\".format(n), \"r\") as file:\n",
    "        features_fc_class.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class= ['/class/O_WC_A_', '/class/O_WC_WO_', '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "name_class_fc=['fc_all_class_O','fc_ill_class_O', 'fc_all_class_P', 'fc_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: fc_all_class_O activation\n",
      "Ya existe el hyperparametro: fc_all_class_O solver\n",
      "Ya existe el hyperparametro: fc_all_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_class_O\n",
      "Ya existe el hyperparametro: fc_ill_class_O activation\n",
      "Ya existe el hyperparametro: fc_ill_class_O solver\n",
      "Ya existe el hyperparametro: fc_ill_class_O hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_class_O\n",
      "Ya existe el hyperparametro: fc_all_class_P activation\n",
      "Ya existe el hyperparametro: fc_all_class_P solver\n",
      "Ya existe el hyperparametro: fc_all_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_class_P\n",
      "Ya existe el hyperparametro: fc_ill_class_P activation\n",
      "Ya existe el hyperparametro: fc_ill_class_P solver\n",
      "Ya existe el hyperparametro: fc_ill_class_P hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_class_P\n"
     ]
    }
   ],
   "source": [
    "for p, n, f in zip(path_class, name_class_fc, features_fc_class):\n",
    "    for m in param:        \n",
    "        if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "            print('Ya existe el hyperparametro:', n, m)\n",
    "        else:\n",
    "            hyper_MLP(p, f, n, m,True)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()\n",
    "    \n",
    "    if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_MLP(p, f, n, True)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados_etiquetas(names):\n",
    "    for n in  names:\n",
    "        print(n)\n",
    "        print()\n",
    "        hyper=[]\n",
    "        for p in param:\n",
    "            hyper.append(pd.read_csv('results/MLP/MLP_hyper_{}_{}.csv'.format(p, n)))\n",
    "        Activation = (maximun(hyper[0], param[0]))\n",
    "        print(Activation)\n",
    "        Solver = (maximun(hyper[1], param[1]))\n",
    "        print(Solver)\n",
    "        Layer = Layersint(maximun(hyper[2], param[2]))\n",
    "        print(Layer)\n",
    "\n",
    "        predict = pd.read_csv('results/MLP/MLP_predict_{}.csv'.format(n))\n",
    "\n",
    "        print('Tasa de acierto:', round(np.mean(predict['accuracy']), 3), '+/-', round(np.std(predict['accuracy']), 3))\n",
    "        print('Tasa de Hamming Loss:', round(np.mean(predict['hamming_loss']), 3), '+/-', round(np.std(predict['hamming_loss']), 3))\n",
    "        print('Tasa de precision(macro)', round(np.mean(predict['precision_macro']), 3), '+/-', round(np.std(predict['precision_macro']), 3))\n",
    "        print('Tasa de precision(micro)', round(np.mean(predict['precision_micro']), 3), '+/-', round(np.std(predict['precision_micro']), 3))\n",
    "        print('Tasa de exactitud(macro):', round(np.mean(predict['recall_macro']), 3),  '+/-', round(np.std(predict['recall_macro']), 3))\n",
    "        print('Tasa de exactitud(micro):', round(np.mean(predict['recall_micro']), 3),  '+/-', round(np.std(predict['recall_micro']), 3))\n",
    "        print('Tasa F1-Score(macro)', round(np.mean(predict['f1_macro']), 3) , '+/-', round(np.std(predict['f1_macro']),3))\n",
    "        print('Tasa F1-Score(micro)', round(np.mean(predict['f1_micro']), 3) , '+/-', round(np.std(predict['f1_micro']),3))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_all_label_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "185\n",
      "Tasa de acierto: 0.799 +/- 0.016\n",
      "Tasa de Hamming Loss: 0.074 +/- 0.007\n",
      "Tasa de precision(macro) 0.904 +/- 0.015\n",
      "Tasa de precision(micro) 0.942 +/- 0.008\n",
      "Tasa de exactitud(macro): 0.838 +/- 0.016\n",
      "Tasa de exactitud(micro): 0.896 +/- 0.011\n",
      "Tasa F1-Score(macro) 0.868 +/- 0.013\n",
      "Tasa F1-Score(micro) 0.919 +/- 0.007\n",
      "---------------------------------------------------------------\n",
      "freq_ill_label_O\n",
      "\n",
      "relu\n",
      "adam\n",
      "180\n",
      "Tasa de acierto: 0.753 +/- 0.023\n",
      "Tasa de Hamming Loss: 0.093 +/- 0.009\n",
      "Tasa de precision(macro) 0.891 +/- 0.021\n",
      "Tasa de precision(micro) 0.927 +/- 0.015\n",
      "Tasa de exactitud(macro): 0.85 +/- 0.023\n",
      "Tasa de exactitud(micro): 0.913 +/- 0.012\n",
      "Tasa F1-Score(macro) 0.867 +/- 0.015\n",
      "Tasa F1-Score(micro) 0.92 +/- 0.007\n",
      "---------------------------------------------------------------\n",
      "freq_all_label_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "155\n",
      "Tasa de acierto: 0.844 +/- 0.014\n",
      "Tasa de Hamming Loss: 0.057 +/- 0.005\n",
      "Tasa de precision(macro) 0.915 +/- 0.012\n",
      "Tasa de precision(micro) 0.95 +/- 0.007\n",
      "Tasa de exactitud(macro): 0.873 +/- 0.017\n",
      "Tasa de exactitud(micro): 0.927 +/- 0.009\n",
      "Tasa F1-Score(macro) 0.892 +/- 0.012\n",
      "Tasa F1-Score(micro) 0.938 +/- 0.006\n",
      "---------------------------------------------------------------\n",
      "freq_ill_label_P\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "180\n",
      "Tasa de acierto: 0.803 +/- 0.016\n",
      "Tasa de Hamming Loss: 0.071 +/- 0.006\n",
      "Tasa de precision(macro) 0.915 +/- 0.013\n",
      "Tasa de precision(micro) 0.945 +/- 0.007\n",
      "Tasa de exactitud(macro): 0.877 +/- 0.016\n",
      "Tasa de exactitud(micro): 0.932 +/- 0.008\n",
      "Tasa F1-Score(macro) 0.893 +/- 0.012\n",
      "Tasa F1-Score(micro) 0.938 +/- 0.005\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_etiquetas(names_LABEL_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_all_label_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "180\n",
      "Tasa de acierto: 0.842 +/- 0.015\n",
      "Tasa de Hamming Loss: 0.058 +/- 0.006\n",
      "Tasa de precision(macro) 0.941 +/- 0.011\n",
      "Tasa de precision(micro) 0.957 +/- 0.008\n",
      "Tasa de exactitud(macro): 0.886 +/- 0.015\n",
      "Tasa de exactitud(micro): 0.917 +/- 0.011\n",
      "Tasa F1-Score(macro) 0.912 +/- 0.011\n",
      "Tasa F1-Score(micro) 0.937 +/- 0.007\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_O\n",
      "\n",
      "relu\n",
      "adam\n",
      "120\n",
      "Tasa de acierto: 0.823 +/- 0.025\n",
      "Tasa de Hamming Loss: 0.067 +/- 0.01\n",
      "Tasa de precision(macro) 0.937 +/- 0.017\n",
      "Tasa de precision(micro) 0.949 +/- 0.015\n",
      "Tasa de exactitud(macro): 0.904 +/- 0.015\n",
      "Tasa de exactitud(micro): 0.936 +/- 0.01\n",
      "Tasa F1-Score(macro) 0.919 +/- 0.01\n",
      "Tasa F1-Score(micro) 0.943 +/- 0.008\n",
      "---------------------------------------------------------------\n",
      "fc_all_label_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "155\n",
      "Tasa de acierto: 0.903 +/- 0.011\n",
      "Tasa de Hamming Loss: 0.035 +/- 0.004\n",
      "Tasa de precision(macro) 0.955 +/- 0.012\n",
      "Tasa de precision(micro) 0.968 +/- 0.007\n",
      "Tasa de exactitud(macro): 0.934 +/- 0.011\n",
      "Tasa de exactitud(micro): 0.958 +/- 0.006\n",
      "Tasa F1-Score(macro) 0.944 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.963 +/- 0.004\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "145\n",
      "Tasa de acierto: 0.883 +/- 0.015\n",
      "Tasa de Hamming Loss: 0.042 +/- 0.005\n",
      "Tasa de precision(macro) 0.958 +/- 0.008\n",
      "Tasa de precision(micro) 0.969 +/- 0.005\n",
      "Tasa de exactitud(macro): 0.938 +/- 0.012\n",
      "Tasa de exactitud(micro): 0.96 +/- 0.007\n",
      "Tasa F1-Score(macro) 0.947 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.964 +/- 0.005\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_etiquetas(names_label_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_all_label_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "135\n",
      "Tasa de acierto: 0.815 +/- 0.018\n",
      "Tasa de Hamming Loss: 0.069 +/- 0.007\n",
      "Tasa de precision(macro) 0.919 +/- 0.013\n",
      "Tasa de precision(micro) 0.946 +/- 0.008\n",
      "Tasa de exactitud(macro): 0.861 +/- 0.014\n",
      "Tasa de exactitud(micro): 0.905 +/- 0.01\n",
      "Tasa F1-Score(macro) 0.888 +/- 0.011\n",
      "Tasa F1-Score(micro) 0.925 +/- 0.008\n",
      "---------------------------------------------------------------\n",
      "rf_ill_label_O\n",
      "\n",
      "relu\n",
      "adam\n",
      "135\n",
      "Tasa de acierto: 0.786 +/- 0.023\n",
      "Tasa de Hamming Loss: 0.081 +/- 0.009\n",
      "Tasa de precision(macro) 0.918 +/- 0.018\n",
      "Tasa de precision(micro) 0.939 +/- 0.013\n",
      "Tasa de exactitud(macro): 0.874 +/- 0.022\n",
      "Tasa de exactitud(micro): 0.922 +/- 0.014\n",
      "Tasa F1-Score(macro) 0.893 +/- 0.014\n",
      "Tasa F1-Score(micro) 0.93 +/- 0.008\n",
      "---------------------------------------------------------------\n",
      "rf_all_label_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "170\n",
      "Tasa de acierto: 0.877 +/- 0.015\n",
      "Tasa de Hamming Loss: 0.044 +/- 0.005\n",
      "Tasa de precision(macro) 0.935 +/- 0.014\n",
      "Tasa de precision(micro) 0.96 +/- 0.008\n",
      "Tasa de exactitud(macro): 0.906 +/- 0.014\n",
      "Tasa de exactitud(micro): 0.945 +/- 0.008\n",
      "Tasa F1-Score(macro) 0.919 +/- 0.011\n",
      "Tasa F1-Score(micro) 0.952 +/- 0.006\n",
      "---------------------------------------------------------------\n",
      "rf_ill_label_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "190\n",
      "Tasa de acierto: 0.868 +/- 0.012\n",
      "Tasa de Hamming Loss: 0.047 +/- 0.005\n",
      "Tasa de precision(macro) 0.947 +/- 0.011\n",
      "Tasa de precision(micro) 0.966 +/- 0.007\n",
      "Tasa de exactitud(macro): 0.921 +/- 0.012\n",
      "Tasa de exactitud(micro): 0.953 +/- 0.007\n",
      "Tasa F1-Score(macro) 0.933 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.959 +/- 0.004\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_etiquetas(names_label_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados_clases(names):\n",
    "    for n in  names:\n",
    "        print(n)\n",
    "        print()\n",
    "        hyper=[]\n",
    "        for p in param:\n",
    "            hyper.append(pd.read_csv('results/MLP/MLP_hyper_{}_{}.csv'.format(p, n)))\n",
    "        Activation = (maximun(hyper[0], param[0]))\n",
    "        print(Activation)\n",
    "        Solver = (maximun(hyper[1], param[1]))\n",
    "        print(Solver)\n",
    "        Layer = Layersint(maximun(hyper[2], param[2]))\n",
    "        print(Layer)\n",
    "\n",
    "        predict = pd.read_csv('results/MLP/MLP_predict_{}.csv'.format(n))\n",
    "\n",
    "        print('Tasa de acierto:', round(np.mean(predict['accuracy']), 3), '+/-', round(np.std(predict['accuracy']), 3))\n",
    "        print('Tasa de precision', round(np.mean(predict['precision']), 3), '+/-', round(np.std(predict['precision']), 3))\n",
    "        print('Tasa de exactitud:', round(np.mean(predict['recall']), 3),  '+/-', round(np.std(predict['recall']), 3))\n",
    "        print('Tasa F1-Score', round(np.mean(predict['f1']), 3) , '+/-', round(np.std(predict['f1']),3))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq_all_class_O\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "150\n",
      "Tasa de acierto: 0.746 +/- 0.045\n",
      "Tasa de precision 0.752 +/- 0.018\n",
      "Tasa de exactitud: 0.746 +/- 0.045\n",
      "Tasa F1-Score 0.751 +/- 0.018\n",
      "---------------------------------------------------------------\n",
      "freq_ill_class_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "185\n",
      "Tasa de acierto: 0.787 +/- 0.018\n",
      "Tasa de precision 0.782 +/- 0.019\n",
      "Tasa de exactitud: 0.787 +/- 0.018\n",
      "Tasa F1-Score 0.783 +/- 0.019\n",
      "---------------------------------------------------------------\n",
      "freq_all_class_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "135\n",
      "Tasa de acierto: 0.848 +/- 0.013\n",
      "Tasa de precision 0.848 +/- 0.013\n",
      "Tasa de exactitud: 0.848 +/- 0.013\n",
      "Tasa F1-Score 0.847 +/- 0.013\n",
      "---------------------------------------------------------------\n",
      "freq_ill_class_P\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "90\n",
      "Tasa de acierto: 0.819 +/- 0.016\n",
      "Tasa de precision 0.817 +/- 0.017\n",
      "Tasa de exactitud: 0.819 +/- 0.016\n",
      "Tasa F1-Score 0.816 +/- 0.017\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_clases(names_CLASS_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_all_class_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "200\n",
      "Tasa de acierto: 0.849 +/- 0.014\n",
      "Tasa de precision 0.849 +/- 0.014\n",
      "Tasa de exactitud: 0.849 +/- 0.014\n",
      "Tasa F1-Score 0.848 +/- 0.014\n",
      "---------------------------------------------------------------\n",
      "fc_ill_class_O\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "85\n",
      "Tasa de acierto: 0.788 +/- 0.018\n",
      "Tasa de precision 0.788 +/- 0.019\n",
      "Tasa de exactitud: 0.788 +/- 0.018\n",
      "Tasa F1-Score 0.784 +/- 0.019\n",
      "---------------------------------------------------------------\n",
      "fc_all_class_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "125\n",
      "Tasa de acierto: 0.903 +/- 0.01\n",
      "Tasa de precision 0.904 +/- 0.01\n",
      "Tasa de exactitud: 0.903 +/- 0.01\n",
      "Tasa F1-Score 0.903 +/- 0.01\n",
      "---------------------------------------------------------------\n",
      "fc_ill_class_P\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "100\n",
      "Tasa de acierto: 0.88 +/- 0.015\n",
      "Tasa de precision 0.879 +/- 0.016\n",
      "Tasa de exactitud: 0.88 +/- 0.015\n",
      "Tasa F1-Score 0.879 +/- 0.016\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_clases(name_class_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_all_class_O\n",
      "\n",
      "relu\n",
      "sgd\n",
      "145\n",
      "Tasa de acierto: 0.817 +/- 0.014\n",
      "Tasa de precision 0.816 +/- 0.015\n",
      "Tasa de exactitud: 0.817 +/- 0.014\n",
      "Tasa F1-Score 0.815 +/- 0.015\n",
      "---------------------------------------------------------------\n",
      "rf_ill_class_O\n",
      "\n",
      "logistic\n",
      "sgd\n",
      "115\n",
      "Tasa de acierto: 0.752 +/- 0.039\n",
      "Tasa de precision 0.754 +/- 0.022\n",
      "Tasa de exactitud: 0.752 +/- 0.039\n",
      "Tasa F1-Score 0.751 +/- 0.022\n",
      "---------------------------------------------------------------\n",
      "rf_all_class_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "135\n",
      "Tasa de acierto: 0.874 +/- 0.013\n",
      "Tasa de precision 0.875 +/- 0.013\n",
      "Tasa de exactitud: 0.874 +/- 0.013\n",
      "Tasa F1-Score 0.874 +/- 0.013\n",
      "---------------------------------------------------------------\n",
      "rf_ill_class_P\n",
      "\n",
      "relu\n",
      "sgd\n",
      "140\n",
      "Tasa de acierto: 0.861 +/- 0.016\n",
      "Tasa de precision 0.862 +/- 0.016\n",
      "Tasa de exactitud: 0.861 +/- 0.016\n",
      "Tasa F1-Score 0.861 +/- 0.016\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_clases(name_class_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejor configuración"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['fc_class_p_all', 'fc_class_p_ill']\n",
    "names_features=['atc', 'cie', 'cie_atc']\n",
    "features = []\n",
    "for n in names:\n",
    "    for f in names_features:\n",
    "        with open(\"feature_selection/best/{}_{}.txt\".format(n, f), \"r\") as file:\n",
    "            features.append(eval(file.readline()))\n",
    "paths_CLASS = ['/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "names_CLASS=['fc_all_class_P_atc', 'fc_all_class_P_cie', 'fc_all_class_P_cie_atc',\n",
    "             'fc_ill_class_P_atc', 'fc_ill_class_P_cie', 'fc_ill_class_P_cie_atc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: fc_all_class_P_atc activation\n",
      "Ya existe el hyperparametro: fc_all_class_P_atc solver\n",
      "Ya existe el hyperparametro: fc_all_class_P_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_class_P_atc\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie activation\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie solver\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_class_P_cie\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie_atc activation\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie_atc solver\n",
      "Ya existe el hyperparametro: fc_all_class_P_cie_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_class_P_cie_atc\n",
      "Ya existe el hyperparametro: fc_ill_class_P_atc activation\n",
      "Ya existe el hyperparametro: fc_ill_class_P_atc solver\n",
      "Ya existe el hyperparametro: fc_ill_class_P_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_class_P_atc\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie activation\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie solver\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_class_P_cie\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie_atc activation\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie_atc solver\n",
      "Ya existe el hyperparametro: fc_ill_class_P_cie_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_class_P_cie_atc\n"
     ]
    }
   ],
   "source": [
    "k=['all','ill']\n",
    "for p, i in zip(paths_CLASS, k):\n",
    "    if i=='all':\n",
    "        names = names_CLASS[0:4]\n",
    "        feat = features[0:4]\n",
    "    else:\n",
    "        names = names_CLASS[4:8]\n",
    "        feat = features[4:8]\n",
    "    for n, f in zip( names, feat):\n",
    "        for m in param:        \n",
    "            if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "                print('Ya existe el hyperparametro:', n, m)\n",
    "            else:\n",
    "                hyper_MLP(p, f, n, m, True)\n",
    "                print()\n",
    "                print('--------------------------------------------------------')\n",
    "                print()\n",
    "\n",
    "        if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "            print('Ya existe los resultados:', n)\n",
    "        else:\n",
    "            predict_MLP(p, f, n, True)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_all_class_P_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "58\n",
      "Tasa de acierto: 0.742 +/- 0.088\n",
      "Tasa de precision 0.798 +/- 0.038\n",
      "Tasa de exactitud: 0.742 +/- 0.088\n",
      "Tasa F1-Score 0.737 +/- 0.086\n",
      "---------------------------------------------------------------\n",
      "fc_all_class_P_cie\n",
      "\n",
      "tanh\n",
      "sgd\n",
      "46\n",
      "Tasa de acierto: 0.54 +/- 0.094\n",
      "Tasa de precision 0.644 +/- 0.106\n",
      "Tasa de exactitud: 0.54 +/- 0.094\n",
      "Tasa F1-Score 0.548 +/- 0.066\n",
      "---------------------------------------------------------------\n",
      "fc_all_class_P_cie_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "42\n",
      "Tasa de acierto: 0.899 +/- 0.012\n",
      "Tasa de precision 0.9 +/- 0.013\n",
      "Tasa de exactitud: 0.899 +/- 0.012\n",
      "Tasa F1-Score 0.898 +/- 0.013\n",
      "---------------------------------------------------------------\n",
      "fc_ill_class_P_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "36\n",
      "Tasa de acierto: 0.728 +/- 0.075\n",
      "Tasa de precision 0.788 +/- 0.046\n",
      "Tasa de exactitud: 0.728 +/- 0.075\n",
      "Tasa F1-Score 0.721 +/- 0.077\n",
      "---------------------------------------------------------------\n",
      "fc_ill_class_P_cie\n",
      "\n",
      "relu\n",
      "sgd\n",
      "52\n",
      "Tasa de acierto: 0.328 +/- 0.112\n",
      "Tasa de precision 0.597 +/- 0.066\n",
      "Tasa de exactitud: 0.328 +/- 0.112\n",
      "Tasa F1-Score 0.483 +/- 0.127\n",
      "---------------------------------------------------------------\n",
      "fc_ill_class_P_cie_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "22\n",
      "Tasa de acierto: 0.89 +/- 0.014\n",
      "Tasa de precision 0.891 +/- 0.014\n",
      "Tasa de exactitud: 0.89 +/- 0.014\n",
      "Tasa F1-Score 0.889 +/- 0.014\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_clases(names_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['fc_label_p_all', 'fc_label_p_ill']\n",
    "names_features=['atc', 'cie', 'cie_atc']\n",
    "features = []\n",
    "for n in names:\n",
    "    for f in names_features:\n",
    "        with open(\"feature_selection/best/{}_{}.txt\".format(n, f), \"r\") as file:\n",
    "            features.append(eval(file.readline()))\n",
    "    features += [['Edad', 'Sexo']]\n",
    "paths_label = ['/label/P_WL_A_', '/label/P_WL_WO_']\n",
    "names_label=['fc_all_label_P_atc', 'fc_all_label_P_cie', 'fc_all_label_P_cie_atc', 'fc_all_label_P_E_S', \n",
    "             'fc_ill_label_P_atc', 'fc_ill_label_P_cie', 'fc_ill_label_P_cie_atc', 'fc_ill_label_P_E_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ya existe el hyperparametro: fc_all_label_P_atc activation\n",
      "Ya existe el hyperparametro: fc_all_label_P_atc solver\n",
      "Ya existe el hyperparametro: fc_all_label_P_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_P_atc\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie activation\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie solver\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_P_cie\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie_atc activation\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie_atc solver\n",
      "Ya existe el hyperparametro: fc_all_label_P_cie_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_P_cie_atc\n",
      "Ya existe el hyperparametro: fc_all_label_P_E_S activation\n",
      "Ya existe el hyperparametro: fc_all_label_P_E_S solver\n",
      "Ya existe el hyperparametro: fc_all_label_P_E_S hidden_layer_sizes\n",
      "Ya existe los resultados: fc_all_label_P_E_S\n",
      "Ya existe el hyperparametro: fc_ill_label_P_atc activation\n",
      "Ya existe el hyperparametro: fc_ill_label_P_atc solver\n",
      "Ya existe el hyperparametro: fc_ill_label_P_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_P_atc\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie activation\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie solver\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_P_cie\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie_atc activation\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie_atc solver\n",
      "Ya existe el hyperparametro: fc_ill_label_P_cie_atc hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_P_cie_atc\n",
      "Ya existe el hyperparametro: fc_ill_label_P_E_S activation\n",
      "Ya existe el hyperparametro: fc_ill_label_P_E_S solver\n",
      "Ya existe el hyperparametro: fc_ill_label_P_E_S hidden_layer_sizes\n",
      "Ya existe los resultados: fc_ill_label_P_E_S\n"
     ]
    }
   ],
   "source": [
    "k=['all','ill']\n",
    "for p, i in zip(paths_label, k):\n",
    "    if i=='all':\n",
    "        names = names_label[0:4]\n",
    "        feat = features[0:4]\n",
    "    else:\n",
    "        names = names_label[4:8]\n",
    "        feat = features[4:8]\n",
    "    for n, f in zip( names, feat):\n",
    "        for m in param:        \n",
    "            if path.exists('results/MLP/MLP_hyper_{}_{}.csv'.format(m,n)): \n",
    "                print('Ya existe el hyperparametro:', n, m)\n",
    "            else:\n",
    "                hyper_MLP(p, f, n, m, True)\n",
    "                print()\n",
    "                print('--------------------------------------------------------')\n",
    "                print()\n",
    "\n",
    "        if path.exists('results/MLP/MLP_predict_{}.csv'.format(n)): \n",
    "            print('Ya existe los resultados:', n)\n",
    "        else:\n",
    "            predict_MLP(p, f, n, True)\n",
    "            print()\n",
    "            print('--------------------------------------------------------')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc_all_label_P_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "52\n",
      "Tasa de acierto: 0.82 +/- 0.035\n",
      "Tasa de Hamming Loss: 0.067 +/- 0.013\n",
      "Tasa de precision(macro) 0.937 +/- 0.02\n",
      "Tasa de precision(micro) 0.946 +/- 0.027\n",
      "Tasa de exactitud(macro): 0.885 +/- 0.012\n",
      "Tasa de exactitud(micro): 0.91 +/- 0.011\n",
      "Tasa F1-Score(macro) 0.909 +/- 0.011\n",
      "Tasa F1-Score(micro) 0.927 +/- 0.012\n",
      "---------------------------------------------------------------\n",
      "fc_all_label_P_cie\n",
      "\n",
      "relu\n",
      "sgd\n",
      "48\n",
      "Tasa de acierto: 0.455 +/- 0.196\n",
      "Tasa de Hamming Loss: 0.23 +/- 0.094\n",
      "Tasa de precision(macro) 0.724 +/- 0.125\n",
      "Tasa de precision(micro) 0.726 +/- 0.136\n",
      "Tasa de exactitud(macro): 0.853 +/- 0.057\n",
      "Tasa de exactitud(micro): 0.906 +/- 0.056\n",
      "Tasa F1-Score(macro) 0.764 +/- 0.056\n",
      "Tasa F1-Score(micro) 0.794 +/- 0.061\n",
      "---------------------------------------------------------------\n",
      "fc_all_label_P_cie_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "44\n",
      "Tasa de acierto: 0.895 +/- 0.012\n",
      "Tasa de Hamming Loss: 0.037 +/- 0.004\n",
      "Tasa de precision(macro) 0.953 +/- 0.012\n",
      "Tasa de precision(micro) 0.967 +/- 0.007\n",
      "Tasa de exactitud(macro): 0.928 +/- 0.011\n",
      "Tasa de exactitud(micro): 0.953 +/- 0.007\n",
      "Tasa F1-Score(macro) 0.94 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.96 +/- 0.005\n",
      "---------------------------------------------------------------\n",
      "fc_all_label_P_E_S\n",
      "\n",
      "tanh\n",
      "sgd\n",
      "10\n",
      "Tasa de acierto: 0.251 +/- 0.053\n",
      "Tasa de Hamming Loss: 0.33 +/- 0.048\n",
      "Tasa de precision(macro) 0.46 +/- 0.1\n",
      "Tasa de precision(micro) 0.661 +/- 0.061\n",
      "Tasa de exactitud(macro): 0.494 +/- 0.136\n",
      "Tasa de exactitud(micro): 0.63 +/- 0.171\n",
      "Tasa F1-Score(macro) 0.432 +/- 0.102\n",
      "Tasa F1-Score(micro) 0.628 +/- 0.101\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_P_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "48\n",
      "Tasa de acierto: 0.823 +/- 0.015\n",
      "Tasa de Hamming Loss: 0.072 +/- 0.007\n",
      "Tasa de precision(macro) 0.94 +/- 0.011\n",
      "Tasa de precision(micro) 0.948 +/- 0.008\n",
      "Tasa de exactitud(macro): 0.901 +/- 0.013\n",
      "Tasa de exactitud(micro): 0.928 +/- 0.009\n",
      "Tasa F1-Score(macro) 0.919 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.938 +/- 0.006\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_P_cie\n",
      "\n",
      "tanh\n",
      "sgd\n",
      "26\n",
      "Tasa de acierto: 0.551 +/- 0.063\n",
      "Tasa de Hamming Loss: 0.176 +/- 0.029\n",
      "Tasa de precision(macro) 0.785 +/- 0.043\n",
      "Tasa de precision(micro) 0.807 +/- 0.035\n",
      "Tasa de exactitud(macro): 0.884 +/- 0.025\n",
      "Tasa de exactitud(micro): 0.923 +/- 0.016\n",
      "Tasa F1-Score(macro) 0.823 +/- 0.022\n",
      "Tasa F1-Score(micro) 0.86 +/- 0.017\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_P_cie_atc\n",
      "\n",
      "relu\n",
      "sgd\n",
      "54\n",
      "Tasa de acierto: 0.881 +/- 0.015\n",
      "Tasa de Hamming Loss: 0.043 +/- 0.006\n",
      "Tasa de precision(macro) 0.958 +/- 0.009\n",
      "Tasa de precision(micro) 0.969 +/- 0.005\n",
      "Tasa de exactitud(macro): 0.935 +/- 0.011\n",
      "Tasa de exactitud(micro): 0.958 +/- 0.007\n",
      "Tasa F1-Score(macro) 0.946 +/- 0.008\n",
      "Tasa F1-Score(micro) 0.963 +/- 0.005\n",
      "---------------------------------------------------------------\n",
      "fc_ill_label_P_E_S\n",
      "\n",
      "tanh\n",
      "sgd\n",
      "14\n",
      "Tasa de acierto: 0.304 +/- 0.025\n",
      "Tasa de Hamming Loss: 0.288 +/- 0.037\n",
      "Tasa de precision(macro) 0.534 +/- 0.046\n",
      "Tasa de precision(micro) 0.771 +/- 0.012\n",
      "Tasa de exactitud(macro): 0.561 +/- 0.07\n",
      "Tasa de exactitud(micro): 0.72 +/- 0.091\n",
      "Tasa F1-Score(macro) 0.528 +/- 0.049\n",
      "Tasa F1-Score(micro) 0.742 +/- 0.051\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resultados_etiquetas(names_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
