{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical computation\n",
    "import numpy as np\n",
    "import itertools\n",
    "from random import randint\n",
    "# import matplotlib and allow it to plot inline\n",
    "\n",
    "# import sklearn\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# dataframe management\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "%autosave 60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opened (path=''):\n",
    "    \n",
    "    X_training=[]\n",
    "    X_testing=[]\n",
    "    y_training=[]\n",
    "    y_testing=[]\n",
    "           \n",
    "    for j in range(0, 50):\n",
    "        X_training.append(pd.read_csv('test_train_dataset{}{}_X_train.csv'.format(path,j)))\n",
    "        X_testing.append(pd.read_csv('test_train_dataset{}{}_X_test.csv'.format(path, j)))\n",
    "        y_training.append(pd.read_csv('test_train_dataset{}{}_y_train.csv'.format(path, j)))\n",
    "        y_testing.append(pd.read_csv('test_train_dataset{}{}_y_test.csv'.format(path, j)))\n",
    "        \n",
    "    return X_training, X_testing, y_training, y_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency (valor):\n",
    "    max = 0\n",
    "    res = list(valor)[0] \n",
    "    for i in list(valor): \n",
    "        freq = list(valor).count(i) \n",
    "        if freq > max: \n",
    "            max = freq \n",
    "            res = i \n",
    "    valor = res\n",
    "    return valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximun (df, name):\n",
    "    maximun = df.sort_values(by='accuracy_model',ascending=False).head(n=1)\n",
    "    best = list(maximun[name])[0]\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Aplicación del algoritmo Regresión Logística Multinomial \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_RLM(path, features, name):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = opened(path=path)\n",
    "    print('Terminada la apertura de BBDD')\n",
    "    \n",
    "    A1 = [i for i in (10.0 ** -np.arange(-1, 4))]\n",
    "    A2 = [i for i in (0.25*10.0 ** -np.arange(-1, 3))]\n",
    "    A3 = [i for i in (0.5*10.0 ** -np.arange(-1, 3))]\n",
    "    A4 = [i for i in (0.75*10.0 ** -np.arange(-1, 3))]\n",
    "    turn_c = sorted(A1+A2+A3+A4)\n",
    "    turn_c[7] = 0.075\n",
    "            \n",
    "    param_grid = [\n",
    "            {\n",
    "                'C' : turn_c, \n",
    "                'solver':['newton-cg','lbfgs']\n",
    "            }\n",
    "           ]\n",
    "\n",
    "    RLM_evaluate=[]\n",
    "    RLM_acc_model=[]\n",
    "    RLM_acc_class=[]\n",
    "    RLM_std=[]\n",
    "\n",
    "\n",
    "    mean=[]\n",
    "    std=[]\n",
    "    best_c=[]\n",
    "    best_solver=[]\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(0, 50):\n",
    "        \n",
    "        droping=pd.concat([x_train[j][features], y_train[j]], axis=1,sort=False)\n",
    "        droping=droping.drop_duplicates(subset=features, keep=False)\n",
    "        xtrain= droping[features]\n",
    "        ytrain=droping['CRG']\n",
    "        \n",
    "        print('Particion: ', j)\n",
    "    #Normalizamos x_test y x_train con la misma media y variancia que x_train\n",
    "        ss=StandardScaler()\n",
    "        ss.fit(xtrain)\n",
    "        ss_train=ss.transform(xtrain)\n",
    "\n",
    "    #Buscamos los mejores parametros para esa división normalizada  \n",
    "        clf = GridSearchCV(LogisticRegression(multi_class='multinomial', max_iter=400,n_jobs=-1), param_grid, \n",
    "                                scoring='accuracy', cv=KFold(n_splits=5), n_jobs=-1)\n",
    "        clf.fit(ss_train,ytrain.values.ravel())\n",
    "\n",
    "\n",
    "    #Evaluamos el algortimo teniendo en cuenta que para la función GridSearchCV test es nuestro train\n",
    "        best_index_Acc = np.nonzero(clf.cv_results_['rank_test_score'] == 1)[0][0]\n",
    "        best_c.append(clf.best_params_['C'])\n",
    "        best_solver.append(clf.best_params_['solver'])\n",
    "\n",
    "        RLM_acc_model.append(clf.cv_results_['mean_test_score'][best_index_Acc])\n",
    "        RLM_std.append(clf.cv_results_['std_test_score'][best_index_Acc])\n",
    "\n",
    "        RLM_evaluate.append([best_c[j], best_solver[j],\n",
    "                             round(RLM_acc_model[j],3), round(RLM_std[j],3)])\n",
    "    \n",
    "             \n",
    "    labels_comp = ['c','solver','accuracy_model', 'std']\n",
    "\n",
    "    comparacion=pd.DataFrame(data=RLM_evaluate, columns = labels_comp)\n",
    "\n",
    "    comparacion.to_csv('results/RLM/RLM_hyper_{}.csv'.format(name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_RLM(path, features, name):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = opened(path=path)\n",
    "    print('Terminada la apertura de BBDD')\n",
    "    \n",
    "    comparacion = pd.read_csv('results/RLM/RLM_hyper_{}.csv'.format(name))\n",
    "    C = maximun(comparacion, 'c')\n",
    "    print('C: ', C)\n",
    "    Solver = maximun(comparacion, 'solver')\n",
    "    print('Solver: ', Solver)\n",
    "    \n",
    "    print('Con los parámetros óptimos procedemos a clasificar.')\n",
    "    \n",
    "   \n",
    "    average_accuracy=[]\n",
    "    average_precision=[]\n",
    "    average_recall=[]\n",
    "    f1_scores=[]\n",
    "    \n",
    "    for i in range(0,50):\n",
    "        \n",
    "        droping_train=pd.concat([x_train[i][features], y_train[i]], axis=1,sort=False)\n",
    "        droping_train=droping_train.drop_duplicates(subset=features, keep=False)\n",
    "        xtrain= droping_train[features]\n",
    "        ytrain=droping_train['CRG']\n",
    "\n",
    "        droping_test=pd.concat([x_test[i][features], y_test[i]], axis=1,sort=False)\n",
    "        droping=droping_test.drop_duplicates(subset=features, keep=False)\n",
    "        xtest= droping_test[features]\n",
    "        ytest=droping_test['CRG']\n",
    "        \n",
    "        ss=StandardScaler()\n",
    "        ss.fit(xtrain)\n",
    "        ss_train=ss.transform(xtrain)\n",
    "        ss_test=ss.transform(xtest)\n",
    "\n",
    "        clf= LogisticRegression(multi_class='multinomial', \n",
    "                                n_jobs=-1,C=C,solver=Solver)\n",
    "\n",
    "        clf.fit(ss_train,ytrain].values.ravel())\n",
    "\n",
    "    #Predecimos el algoritmo con el mejor K\n",
    "        y_true, y_pred = ytest, clf.predict(ss_test)\n",
    "\n",
    "        cm = confusion_matrix(y_true,y_pred)\n",
    "        TP = np.diag(cm)\n",
    "        FP = np.sum(cm, axis=0) - TP\n",
    "        FN = np.sum(cm, axis=1) - TP\n",
    "        #num_classes = len(TP)\n",
    "        #TN = []\n",
    "        #for i in range(num_classes):\n",
    "            #temp = np.delete(cm, i, 0)    # delete ith row\n",
    "            #temp = np.delete(temp, i, 1)  # delete ith column\n",
    "            #TN.append(sum(sum(temp)))\n",
    "\n",
    "        precision=TP / (TP + FP)\n",
    "        recall=TP / (TP + FN)\n",
    "\n",
    "        average_precision.append(np.mean(TP / (TP + FP)))\n",
    "        average_recall.append(np.mean(TP / (TP + FN)))\n",
    "        f1_scores.append(np.mean(2*(precision*recall)/(precision+recall)))\n",
    "        average_accuracy.append(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    predict=pd.DataFrame()\n",
    "\n",
    "    predict['accuracy']=average_accuracy\n",
    "    predict['precision']=average_precision\n",
    "    predict['recall']=average_recall\n",
    "    predict['f1']=f1_scores\n",
    "    predict.to_csv('results/RLM/RLM_predict_{}.csv'.format(name), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucles para las diferentes ejecuciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de caracteristicas: Frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['ocurrencia_all', 'ocurrencia_ill', 'presencia_all', 'presencia_ill'] \n",
    "features_freq = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/freq_{}.txt\".format(n), \"r\") as file:\n",
    "        features_freq.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_CLASS = ['/class/O_WC_A_','/class/O_WC_WO_' , '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "names_CLASS_fr=['freq_all_class_O', 'freq_ill_class_O', 'freq_all_class_P', 'freq_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, n, f in zip(paths_CLASS, names_CLASS_fr, features_freq):\n",
    "    if path.exists('results/RLM/RLM_hyper_{}.csv'.format(n)): \n",
    "        print('Ya existe el hyperparametro:', n)\n",
    "    else:\n",
    "        hyper_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()\n",
    "    \n",
    "    if path.exists('results/RLM/RLM_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Caracteriticas: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['class_o_all','class_o_ill', 'class_p_all', 'class_p_ill']\n",
    "features_rf_class = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/rf_{}.txt\".format(n), \"r\") as file:\n",
    "        features_rf_class.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class= ['/class/O_WC_A_', '/class/O_WC_WO_', '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "name_class_rf=['rf_all_class_O','rf_ill_class_O', 'rf_all_class_P', 'rf_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, n, f in zip(path_class, name_class_rf, features_rf_class):\n",
    "    if path.exists('results/RLM/RLM_hyper_{}.csv'.format(n)): \n",
    "        print('Ya existe el hyperparametro:', n)\n",
    "    else:\n",
    "        hyper_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()\n",
    "    \n",
    "    if path.exists('results/RLM/RLM_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de caracteristicas: F Fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['class_o_all','class_o_ill', 'class_p_all', 'class_p_ill']\n",
    "features_fc_class = []\n",
    "for n in names:\n",
    "    with open(\"feature_selection/rf_{}.txt\".format(n), \"r\") as file:\n",
    "        features_fc_class.append(eval(file.readline()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class= ['/class/O_WC_A_', '/class/O_WC_WO_', '/class/P_WC_A_', '/class/P_WC_WO_']\n",
    "name_class_fc=['fc_all_class_O','fc_ill_class_O', 'fc_all_class_P', 'fc_ill_class_P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, n, f in zip(path_class, name_class_fc, features_fc_class):\n",
    "    if path.exists('results/RLM/RLM_hyper_{}.csv'.format(n)): \n",
    "        print('Ya existe el hyperparametro:', n)\n",
    "    else:\n",
    "        hyper_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()\n",
    "    \n",
    "    if path.exists('results/RLM/RLM_predict_{}.csv'.format(n)): \n",
    "        print('Ya existe los resultados:', n)\n",
    "    else:\n",
    "        predict_RLM(p, f, n)\n",
    "        print()\n",
    "        print('--------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados(names):\n",
    "    hyper=[]\n",
    "    predict_class=[]\n",
    "    for name in names:\n",
    "        hyper.append(pd.read_csv('results/RLM/RLM_hyper_{}.csv'.format(name)))\n",
    "        predict_class.append(pd.read_csv('results/RLM/RLM_predict_{}.csv'.format(name)))\n",
    "        \n",
    "    for i, n in zip(range(0, len(names)), names):\n",
    "        print(n)\n",
    "        print()\n",
    "        C = maximun(hyper[i], 'c')\n",
    "        print('C: ', C)\n",
    "        Solver = maximun(hyper[i], 'solver')\n",
    "        print('Solver: ', Solver)\n",
    "\n",
    "        print('Tasa de acierto:', round(np.mean(predict_class[i]['accuracy']), 3), '+/-', round(np.std(predict_class[i]['accuracy']), 3))\n",
    "        print('Tasa de precision', round(np.mean(predict_class[i]['precision']), 3), '+/-', round(np.std(predict_class[i]['precision']), 3))\n",
    "        print('Tasa de exactitud:', round(np.mean(predict_class[i]['recall']), 3),  '+/-', round(np.std(predict_class[i]['recall']), 3))\n",
    "        print('Tasa F1-Score', round(np.mean(predict_class[i]['f1']), 3) , '+/-', round(np.std(predict_class[i]['f1']),3))\n",
    "        print('---------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultados(names_CLASS_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados(name_class_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados(name_class_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
